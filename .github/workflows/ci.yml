name: CI

on:
  push:
    branches: ["main", "docs/**"]
  pull_request:
    branches: ["main"]
  workflow_dispatch:
    inputs:
      run_full_suite:
        description: "Run full test suite manually (unit + integration + adapters + e2e)."
        required: false
        default: "false"
        type: choice
        options:
          - "false"
          - "true"
      run_e2e:
        description: "Run E2E tests (docker-compose + Playwright) manually."
        required: false
        default: "false"
        type: choice
        options:
          - "false"
          - "true"

permissions:
  contents: read

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  PYTHON_VERSION: "3.11"
  RUFF_VERSION: "0.5.6"

jobs:
  lint:
    name: Lint (ruff)
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: "pip"

      - name: Install ruff only
        run: |
          python -m pip install --upgrade pip
          python -m pip install ruff==${{ env.RUFF_VERSION }}
          python -m pip install black==24.8.0

      - name: Show formatter versions
        run: |
          black --version
          ruff --version

      - name: Run ruff check
        run: ruff check .

      - name: Run black format check
        run: black --check src tests

  test-unit:
    name: Unit Tests (Coverage Policy)
    runs-on: ubuntu-latest
    needs: [lint]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install -r requirements.txt

      - name: Run unit tests with coverage
        env:
          STRICT_KWARGS_CONTRACT: "1"
        run: |
          python -m pytest tests/unit \
            --cov=src \
            --cov-report=term-missing \
            --cov-report=json \
            -v

      - name: Validate domain coverage (100% required)
        run: |
          python -m coverage report \
            --include="src/domain/*" \
            --fail-under=100

      - name: Validate application coverage (80% required)
        run: |
          python -m coverage report \
            --include="src/application/*" \
            --fail-under=80

      - name: Generate HTML coverage
        run: python -m coverage html

      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage-report
          path: htmlcov/
          retention-days: 7

  test-integration:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [lint]

    services:
      postgres:
        image: postgres:16-alpine
        env:
          POSTGRES_USER: scenario
          POSTGRES_PASSWORD: scenario
          POSTGRES_DB: scenario
        options: >-
          --health-cmd "pg_isready -U scenario -d scenario"
          --health-interval 5s
          --health-timeout 3s
          --health-retries 10
          --health-start-period 5s
        ports:
          - 5432:5432

    env:
      DATABASE_URL: postgresql://scenario:scenario@localhost:5432/scenario
      DATABASE_URL_TEST: postgresql://scenario:scenario@localhost:5432/scenario_test
      APP_ENV: dev
      RUN_DB_TESTS: "1"

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install -r requirements.txt

      - name: Install postgres client
        run: |
          sudo apt-get update -qq
          sudo apt-get install -y -qq postgresql-client

      - name: Wait for Postgres to be ready
        env:
          PGPASSWORD: scenario
        run: |
          set -euo pipefail
          echo "Waiting for Postgres (max 60s)..."
          for i in $(seq 1 30); do
            if pg_isready -h localhost -U scenario -d scenario -q; then
              echo "Postgres is ready (attempt $i)"
              exit 0
            fi
            sleep 2
          done
          echo "::error::Postgres did not become ready in 60s"
          exit 1

      - name: Create test database (scenario_test)
        env:
          PGPASSWORD: scenario
        run: |
          set -euo pipefail
          psql -h localhost -U scenario -d scenario -c "SELECT 1;"
          psql -h localhost -U scenario -d scenario -tc \
            "SELECT 1 FROM pg_database WHERE datname='scenario_test'" \
            | grep -q 1 \
            || psql -h localhost -U scenario -d scenario -c "CREATE DATABASE scenario_test;"

      - name: Run database migrations (scenario + scenario_test)
        run: |
          set -euo pipefail
          export PYTHONPATH=src
          # Migrate main DB (scenario)
          alembic upgrade head
          # Migrate test DB (scenario_test)
          export DATABASE_URL="${DATABASE_URL_TEST}"
          alembic upgrade head

      - name: DB integration tests (must run, no skips)
        shell: bash
        run: |
          set -euo pipefail

          echo "Collect DB tests..."
          COLLECT_OUT=$(python -m pytest tests/integration -m db --collect-only -q 2>&1 || true)
          echo "$COLLECT_OUT"

          # Fail if no tests were collected
          if echo "$COLLECT_OUT" | grep -qiE "collected 0 items|no tests collected|no tests ran"; then
            echo "::error::No DB tests were collected. Check @pytest.mark.db markers."
            exit 1
          fi

          echo "Run DB tests..."
          RUN_OUT=$(python -m pytest tests/integration -m db -v --tb=short 2>&1)
          echo "$RUN_OUT"

          # Fail if any test was skipped
          if echo "$RUN_OUT" | grep -qiE "[0-9]+ skipped"; then
            echo "::error::DB tests were skipped in CI. They must all run when RUN_DB_TESTS=1."
            exit 1
          fi

          echo "DB tests OK (no skips)."

      - name: Integration tests (non-DB)
        shell: bash
        run: |
          set -euo pipefail
          python -m pytest tests/integration -m "not db" -v


  docker-build:
    name: Docker Build
    runs-on: ubuntu-latest
    needs: [lint]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: false
          tags: scenariobuilder:test
          cache-from: type=gha
          cache-to: type=gha,mode=max
          target: final

      - name: Test docker-compose config
        run: docker compose config

  manual-full-suite:
    name: Manual - Full Suite (on demand)
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' && inputs.run_full_suite == 'true'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install -r requirements.txt

      - name: Run all tests (manual)
        run: python -m pytest tests -v --tb=short

      - name: Generate coverage report (manual)
        run: |
          python -m pytest tests \
            --cov=src \
            --cov-report=html \
            --cov-report=term-missing

      - name: Upload coverage report (manual)
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage-report-manual
          path: htmlcov/
          retention-days: 7

  manual-e2e:
    name: Manual - E2E (docker-compose + Playwright)
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' && inputs.run_e2e == 'true'
    timeout-minutes: 30
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install -r requirements.txt

      - name: Install Playwright browsers
        run: |
          python -m playwright install --with-deps

      - name: Build & start stack
        run: |
          docker compose up -d --build

      - name: Wait for API health
        run: |
          echo "Waiting for API health (max 120s)..."
          for i in $(seq 1 60); do
            if curl -fsS http://localhost:8000/health > /dev/null 2>&1; then
              echo "API is healthy (attempt $i)"
              exit 0
            fi
            sleep 2
          done
          echo "ERROR: API did not become healthy in 120s"
          docker compose ps
          docker compose logs --no-color --tail=50
          exit 1

      - name: Run E2E tests (marker:e2e)
        env:
          API_BASE_URL: http://localhost:8000
          UI_BASE_URL: http://localhost:7860
        run: |
          python -m pytest -q -m e2e

      - name: Dump logs on failure
        if: failure()
        run: |
          docker compose ps
          docker compose logs --no-color --tail=200

      - name: Shutdown
        if: always()
        run: |
          docker compose down -v
